{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfAi/2OfB3d8LIUIEFUriq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedamusk/.py/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "CuZ7AbfsptKE",
        "outputId": "a155ded7-d1a2-47e2-bf93-4b723f9f2e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/10000 [00:00<?, ?epoch/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for dimension 1 with size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2bb24dfe4da0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-2bb24dfe4da0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;31m# Create the PINN model and train it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImprovedPINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pinn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;31m# Plot the loss curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2bb24dfe4da0>\u001b[0m in \u001b[0;36mtrain_pinn\u001b[0;34m(model, t_data, xy_data, n_epochs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# Compute the physics-based loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mphys_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphysics_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Gradually increase the weight of the physics loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2bb24dfe4da0>\u001b[0m in \u001b[0;36mphysics_loss\u001b[0;34m(model, t, normalize)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Compute the residuals of the second order ODE: d²xy/dt² + k * xy / r³ = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mresidual_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2xy_dt2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mresidual_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2xy_dt2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class ImprovedPINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Define a deeper and wider network\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(1, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "        # Apply Xavier initialization for all Linear layers\n",
        "        for layer in self.network:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_normal_(layer.weight)\n",
        "                nn.init.zeros_(layer.bias)\n",
        "\n",
        "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
        "        return self.network(t)\n",
        "\n",
        "    def compute_derivatives(self, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Computes the output, its first derivative, and second derivative with respect to time t.\n",
        "        \"\"\"\n",
        "        # Ensure gradients are computed with respect to t\n",
        "        t.requires_grad_(True)\n",
        "        xy = self.forward(t)\n",
        "\n",
        "        # Compute first derivative d(xy)/dt\n",
        "        dxy_dt = torch.autograd.grad(\n",
        "            outputs=xy, inputs=t,\n",
        "            grad_outputs=torch.ones_like(xy),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        # Compute second derivative d^2(xy)/dt^2\n",
        "        d2xy_dt2 = torch.autograd.grad(\n",
        "            outputs=dxy_dt, inputs=t,\n",
        "            grad_outputs=torch.ones_like(dxy_dt),\n",
        "            create_graph=True\n",
        "        )[0]\n",
        "\n",
        "        return xy, dxy_dt, d2xy_dt2\n",
        "\n",
        "\n",
        "def generate_orbital_data(n_points: int = 1000, noise_level: float = 0.005) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Generates orbital data (with reduced noise) for a stable circular orbit.\n",
        "\n",
        "    Returns:\n",
        "        t: Time array.\n",
        "        x: X-coordinate positions.\n",
        "        y: Y-coordinate positions.\n",
        "    \"\"\"\n",
        "    t = np.linspace(0, 10, n_points)\n",
        "    r = 1.0          # orbital radius\n",
        "    omega = 2 * np.pi / 5  # angular velocity\n",
        "\n",
        "    x = r * np.cos(omega * t)\n",
        "    y = r * np.sin(omega * t)\n",
        "\n",
        "    # Add small noise to simulate measurement error\n",
        "    x += noise_level * np.random.randn(n_points)\n",
        "    y += noise_level * np.random.randn(n_points)\n",
        "\n",
        "    return t, x, y\n",
        "\n",
        "\n",
        "def physics_loss(model: ImprovedPINN, t: torch.Tensor, normalize: bool = True) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the physics-informed loss by enforcing the orbital dynamics ODE.\n",
        "\n",
        "    Args:\n",
        "        model: The PINN model.\n",
        "        t: Input tensor for time.\n",
        "        normalize: Whether to normalize the physics residual.\n",
        "\n",
        "    Returns:\n",
        "        A scalar tensor representing the physics loss.\n",
        "    \"\"\"\n",
        "    xy, dxy_dt, d2xy_dt2 = model.compute_derivatives(t)\n",
        "\n",
        "    # Gravitational parameter for the two-body problem (assuming unit masses and G=1)\n",
        "    k = 4 * np.pi ** 2\n",
        "\n",
        "    # Compute the distance from the origin\n",
        "    r = torch.sqrt(xy[:, 0] ** 2 + xy[:, 1] ** 2)\n",
        "\n",
        "    # Compute the residuals of the second order ODE: d²xy/dt² + k * xy / r³ = 0\n",
        "    residual_x = d2xy_dt2[:, 0] + k * xy[:, 0] / (r ** 3)\n",
        "    residual_y = d2xy_dt2[:, 1] + k * xy[:, 1] / (r ** 3)\n",
        "\n",
        "    if normalize:\n",
        "        # Normalize the residuals by the average magnitude of the gravitational term\n",
        "        scale = torch.mean(torch.abs(k * xy / (r ** 3).unsqueeze(1)))\n",
        "        residual_x /= scale\n",
        "        residual_y /= scale\n",
        "\n",
        "    return torch.mean(residual_x ** 2 + residual_y ** 2)\n",
        "\n",
        "\n",
        "def train_pinn(model: ImprovedPINN,\n",
        "               t_data: np.ndarray,\n",
        "               xy_data: np.ndarray,\n",
        "               n_epochs: int = 10000) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Trains the PINN model using both data loss and physics-informed loss.\n",
        "\n",
        "    Args:\n",
        "        model: The PINN model.\n",
        "        t_data: Numpy array of time data.\n",
        "        xy_data: Numpy array of shape (n_points, 2) containing x and y positions.\n",
        "        n_epochs: Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the training losses.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=100, factor=0.5)\n",
        "\n",
        "    # Convert data to torch tensors and move to device\n",
        "    t_torch = torch.FloatTensor(t_data).view(-1, 1).to(device)\n",
        "    xy_torch = torch.FloatTensor(xy_data).to(device)\n",
        "\n",
        "    # Normalize the position data\n",
        "    xy_scale = torch.max(torch.abs(xy_torch))\n",
        "    xy_torch /= xy_scale\n",
        "\n",
        "    # To track losses\n",
        "    losses = {\n",
        "        \"total_loss\": [],\n",
        "        \"data_loss\": [],\n",
        "        \"physics_loss\": []\n",
        "    }\n",
        "    best_loss = float('inf')\n",
        "    best_state: Dict[str, Any] = {}\n",
        "\n",
        "    # Training loop with progress bar\n",
        "    for epoch in tqdm(range(n_epochs), desc=\"Training\", unit=\"epoch\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass for data loss\n",
        "        xy_pred = model(t_torch)\n",
        "        data_loss = torch.mean((xy_pred - xy_torch) ** 2)\n",
        "\n",
        "        # Compute the physics-based loss\n",
        "        phys_loss = physics_loss(model, t_torch)\n",
        "\n",
        "        # Gradually increase the weight of the physics loss\n",
        "        physics_weight = 0.01 * (1 - np.exp(-epoch / 1000))\n",
        "        total_loss = data_loss + physics_weight * phys_loss\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step(total_loss)\n",
        "\n",
        "        # Record losses\n",
        "        losses[\"total_loss\"].append(total_loss.item())\n",
        "        losses[\"data_loss\"].append(data_loss.item())\n",
        "        losses[\"physics_loss\"].append(phys_loss.item())\n",
        "\n",
        "        # Save the best model (lowest total loss)\n",
        "        if total_loss.item() < best_loss:\n",
        "            best_loss = total_loss.item()\n",
        "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "\n",
        "        if (epoch + 1) % 500 == 0:\n",
        "            tqdm.write(f'Epoch [{epoch + 1}/{n_epochs}] - Total Loss: {total_loss.item():.4f}, '\n",
        "                       f'Data Loss: {data_loss.item():.4f}, Physics Loss: {phys_loss.item():.4f}')\n",
        "\n",
        "    # Load the best model parameters\n",
        "    model.load_state_dict(best_state)\n",
        "    return {key: np.array(val) for key, val in losses.items()}\n",
        "\n",
        "\n",
        "def plot_losses(losses: Dict[str, np.ndarray]) -> None:\n",
        "    \"\"\"\n",
        "    Plots the training losses on a semilog scale.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.semilogy(losses[\"total_loss\"], label='Total Loss')\n",
        "    plt.semilogy(losses[\"data_loss\"], label='Data Loss')\n",
        "    plt.semilogy(losses[\"physics_loss\"], label='Physics Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss (log scale)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_results(t_data: np.ndarray, xy_data: np.ndarray, model: ImprovedPINN, xy_scale: float) -> None:\n",
        "    \"\"\"\n",
        "    Plots the predicted orbit and time series comparisons.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        t_torch = torch.FloatTensor(t_data).view(-1, 1).to(device)\n",
        "        xy_pred = model(t_torch).cpu().numpy() * xy_scale  # Denormalize predictions\n",
        "\n",
        "    # Plot orbit\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(121)\n",
        "    plt.plot(xy_data[:, 0], xy_data[:, 1], 'b.', label='Data')\n",
        "    plt.plot(xy_pred[:, 0], xy_pred[:, 1], 'r-', label='PINN Prediction')\n",
        "    plt.plot(0, 0, 'y*', markersize=15, label='Central Body')\n",
        "    plt.xlabel('X Position')\n",
        "    plt.ylabel('Y Position')\n",
        "    plt.legend()\n",
        "    plt.axis('equal')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot x position over time\n",
        "    plt.subplot(122)\n",
        "    plt.plot(t_data, xy_data[:, 0], 'b.', label='Data X')\n",
        "    plt.plot(t_data, xy_pred[:, 0], 'r-', label='PINN X')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('X Position')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    # Generate orbital data\n",
        "    t_data, x_data, y_data = generate_orbital_data()\n",
        "    xy_data = np.stack([x_data, y_data], axis=1)\n",
        "\n",
        "    # Create the PINN model and train it\n",
        "    model = ImprovedPINN()\n",
        "    losses = train_pinn(model, t_data, xy_data)\n",
        "\n",
        "    # Plot the loss curves\n",
        "    plot_losses(losses)\n",
        "\n",
        "    # For plotting predictions, we need the scaling factor used during training.\n",
        "    # Since data was normalized by the max absolute value, we recalcualte that here.\n",
        "    xy_scale = np.max(np.abs(xy_data))\n",
        "    plot_results(t_data, xy_data, model, xy_scale)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}